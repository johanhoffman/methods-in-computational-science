{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "template-report-lab-X.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/methods-in-computational-science/blob/main/MICS_Vector_Spaces_jacwah.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 1: Introduction**\n",
        "**Jacob Wahlgren**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJipbXtnjrJZ"
      },
      "source": [
        "The first problem set was an introduction to the course. This report includes implementations of basic linear algebra algorithms such as the scalar product and Euclidian norm as well as simple tests to verify their accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "The code was written by the author (Jacob Wahlgren), based on a template by Johan Hoffman."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e"
      },
      "source": [
        "# Copyright (C) 2020,2021 Johan Hoffman (jhoffman@kth.se)\n",
        "# Copyright (C) 2021 Jacob Wahlgren (jacobwah@kth.se)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "#try:\n",
        "#    from dolfin import *; from mshr import *\n",
        "#except ImportError as e:\n",
        "#    !apt-get install -y -qq software-properties-common \n",
        "#    !add-apt-repository -y ppa:fenics-packages/fenics\n",
        "#    !apt-get update -qq\n",
        "#    !apt install -y --no-install-recommends fenics\n",
        "#    from dolfin import *; from mshr import *\n",
        "    \n",
        "#import dolfin.common.plotting as fenicsplot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "The first problem set is an introduction. The goals are to get famailiar with using the tools and methods that will be used for the rest of the course. The algorithms are based on formulas given in the lecture notes. The numpy package includes faster implementations of these operations, and there are more advanced algorithms for e.g. the matrix-matrix product that has a better computational complexity (see [Matrix multiplication algorithm](https://en.wikipedia.org/wiki/Matrix_multiplication_algorithm) on Wikipedia).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4iBj5VURZx"
      },
      "source": [
        "The scalar product, or Euclidian inner product, is defined in Example 1.6 as $(x,y) = x_1 y_1 + ... + x_n y_n$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6ekPKxWWU7S"
      },
      "source": [
        "def scalar_product(x, y):\n",
        "  assert(len(x) == len(y))\n",
        "  p = 0\n",
        "  for i in range(len(x)):\n",
        "    p += x[i] * y[i]\n",
        "  return p"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYbSY3ZlDshr"
      },
      "source": [
        "In section 2.2 the matrix-vector product $Ax$ of matrix $A$ and column vector $x$ is defined as an $m$-dimensional column vector $y=(y_i)$ such that\n",
        "\n",
        "$\\displaystyle y_i = \\sum_{j=1}^n a_{ij} x_j$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSAoSAkFEvKX"
      },
      "source": [
        "def matrix_vector_product(a, x):\n",
        "  m, n = np.shape(a)\n",
        "  assert(len(x) == n)\n",
        "  y = np.zeros(m)\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      y[i] += a[(i,j)] * x[j]\n",
        "  return y"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnKob_syJf_y"
      },
      "source": [
        "The matrix-matrix product $C=AB$ is defined in equation (2.2) in section 2.3, where $C \\in R^{m \\times n}$, $A \\in R^{m \\times l}$ and $B \\in R^{l \\times n}$.\n",
        "\n",
        "$\\displaystyle c_{ij} = \\sum^l_{k=1} a_{ik} b_{kj}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nniFHhZLYiJ"
      },
      "source": [
        "def matrix_matrix_product(a, b):\n",
        "  m, l = np.shape(a)\n",
        "  l2, n = np.shape(b)\n",
        "  assert(l == l2)\n",
        "  c = np.zeros((m, n))\n",
        "  for i in range(m):\n",
        "    for j in range(n):\n",
        "      for k in range(l):\n",
        "        c[(i,j)] += a[(i,k)] * b[(k,j)]\n",
        "  return c"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5TjGD9YPOWI"
      },
      "source": [
        "The Euclidian norm of a vector $x$ is defined in example 1.3.\n",
        "\n",
        "$\\displaystyle ||x|| = (x_1^2 + ... + x_n^2)^\\frac{1}{2}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKHs0mAXPv6R"
      },
      "source": [
        "def euclidian_norm(x):\n",
        "  norm = 0\n",
        "  for i in range(len(x)):\n",
        "    norm += x[i]**2\n",
        "  norm = np.sqrt(norm)\n",
        "  return norm"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdNRqN-oRq5_"
      },
      "source": [
        "The Euclidian distance between vectors $x$Â and $y$ is given in the assignment as $||x-y||$. In section 1.2 vector subtraction is defined as the inverse of vector addition, which in turn in defined for the Euclidian space in example 1.1 as element-wise addition. Thus Euclidian vector subtraction can be implemented as element-wise subtraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUFznnSXRycv"
      },
      "source": [
        "def euclidian_distance(x, y):\n",
        "  assert(len(x) == len(y))\n",
        "  z = np.zeros(len(x))\n",
        "  for i in range(len(x)):\n",
        "    z[i] = x[i] - y[i]\n",
        "  return euclidian_norm(z)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "The implementations are tested with some sample data of various dimensions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnqUh6rgYSNF"
      },
      "source": [
        "assert(scalar_product(np.array([1]), np.array([2])) == 2)\n",
        "assert(scalar_product(np.array([1,2,3]), np.array([4,5,6])) == 4+10+18)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6yu7Sp8GNBN"
      },
      "source": [
        "assert(np.array_equal(matrix_vector_product(np.array([[1, 2], [3, 4]]), np.array([5, 6])), np.array([17, 39])))\n",
        "assert(np.array_equal(matrix_vector_product(np.array([[1, 2], [3, 4], [5, 6]]), np.array([7, 8])), np.array([23, 53, 83])))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpSJVfMUL77Q"
      },
      "source": [
        "assert(np.array_equal(matrix_matrix_product(np.array([[1, 2], [3, 4]]), np.array([[5, 6], [7, 8]])), np.array([[19, 22], [43, 50]])))\n",
        "assert(np.array_equal(matrix_vector_product(np.array([[1, 2], [3, 4], [5, 6]]), np.array([[7], [8]])), np.array([23, 53, 83])))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgZLR5jMQP5Q"
      },
      "source": [
        "assert(euclidian_norm(np.array([2])) == 2)\n",
        "assert(euclidian_norm(np.array([3, 4])) == 5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFNCxMetS-Fo"
      },
      "source": [
        "assert(euclidian_distance(np.array([0, 0]), np.array([1, 1])) == np.sqrt(2))\n",
        "assert(euclidian_distance(np.array([4, 3]), np.array([1, -1])) == 5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "The implementations pass the basic test cases. The trickiest part was getting the order of the dimensions correct, which is why it is important to test with non-square matrices."
      ]
    }
  ]
}
